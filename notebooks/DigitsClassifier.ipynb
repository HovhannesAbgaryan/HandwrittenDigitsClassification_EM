{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Ensemble Methods\n",
    "## Experimenting on MNIST dataset\n",
    "\n",
    "Let's use sklearn's implementations of the Bagging, Random Forest, Weighted Voting and Stacking models and perform experiments on MNIST dataset. First, we will use only 2 digits from the dataset and then will use all 10 digits. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd050777291edc11"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-20T18:27:47.210568500Z",
     "start_time": "2024-02-20T18:27:42.338442400Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\") # Plot style\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7592\\3586860171.py:1: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  mnist_train = pd.read_csv('Datasets/mnist_train.csv', header=None)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7592\\3586860171.py:2: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  mnist_test = pd.read_csv('Datasets/mnist_test.csv', header=None)\n"
     ]
    }
   ],
   "source": [
    "mnist_train = pd.read_csv(\"data/raw/mnist_train.csv\", header=None)\n",
    "mnist_test = pd.read_csv(\"data/raw/mnist_test.csv\", header=None)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T18:27:59.855143500Z",
     "start_time": "2024-02-20T18:27:52.852114800Z"
    }
   },
   "id": "4d75c7c8aff7bf56"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "X_train, y_train = mnist_train.iloc[:2000, 1:], mnist_train.iloc[:2000, 0]\n",
    "X_test, y_test = mnist_test.iloc[:1000, 1:], mnist_test.iloc[:1000, 0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T18:28:02.124206900Z",
     "start_time": "2024-02-20T18:28:01.963285100Z"
    }
   },
   "id": "f45504d950e8ad4a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Bagging"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d993e340f9f142a"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(2000, 784)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T18:28:04.681668700Z",
     "start_time": "2024-02-20T18:28:04.457693600Z"
    }
   },
   "id": "37fd7b700ad64951"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[0;32m      2\u001B[0m classifier \u001B[38;5;241m=\u001B[39m BaggingClassifier(n_estimators\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m----> 3\u001B[0m \u001B[43mclassifier\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTime taken: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtime\u001B[38;5;241m.\u001B[39mperf_counter()\u001B[38;5;250m \u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;250m \u001B[39mstart\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m sec\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTrain error rate: \u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m accuracy_score(classifier\u001B[38;5;241m.\u001B[39mpredict(X_train), y_train))\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\main\\lib\\site-packages\\sklearn\\base.py:1151\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1144\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1146\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1147\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1148\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1149\u001B[0m     )\n\u001B[0;32m   1150\u001B[0m ):\n\u001B[1;32m-> 1151\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\main\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:338\u001B[0m, in \u001B[0;36mBaseBagging.fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    329\u001B[0m \u001B[38;5;66;03m# Convert data (X is required to be 2d and indexable)\u001B[39;00m\n\u001B[0;32m    330\u001B[0m X, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_data(\n\u001B[0;32m    331\u001B[0m     X,\n\u001B[0;32m    332\u001B[0m     y,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    336\u001B[0m     multi_output\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    337\u001B[0m )\n\u001B[1;32m--> 338\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_samples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\main\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:394\u001B[0m, in \u001B[0;36mBaseBagging._fit\u001B[1;34m(self, X, y, max_samples, max_depth, sample_weight, check_input)\u001B[0m\n\u001B[0;32m    392\u001B[0m n_samples \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    393\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_samples \u001B[38;5;241m=\u001B[39m n_samples\n\u001B[1;32m--> 394\u001B[0m y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_y\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    396\u001B[0m \u001B[38;5;66;03m# Check parameters\u001B[39;00m\n\u001B[0;32m    397\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_estimator()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\main\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:803\u001B[0m, in \u001B[0;36mBaggingClassifier._validate_y\u001B[1;34m(self, y)\u001B[0m\n\u001B[0;32m    801\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_validate_y\u001B[39m(\u001B[38;5;28mself\u001B[39m, y):\n\u001B[0;32m    802\u001B[0m     y \u001B[38;5;241m=\u001B[39m column_or_1d(y, warn\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m--> 803\u001B[0m     \u001B[43mcheck_classification_targets\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    804\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses_, y \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39munique(y, return_inverse\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    805\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_classes_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses_)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\main\\lib\\site-packages\\sklearn\\utils\\multiclass.py:207\u001B[0m, in \u001B[0;36mcheck_classification_targets\u001B[1;34m(y)\u001B[0m\n\u001B[0;32m    195\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcheck_classification_targets\u001B[39m(y):\n\u001B[0;32m    196\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Ensure that target y is of a non-regression type.\u001B[39;00m\n\u001B[0;32m    197\u001B[0m \n\u001B[0;32m    198\u001B[0m \u001B[38;5;124;03m    Only the following target types (as defined in type_of_target) are allowed:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    205\u001B[0m \u001B[38;5;124;03m        Target values.\u001B[39;00m\n\u001B[0;32m    206\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 207\u001B[0m     y_type \u001B[38;5;241m=\u001B[39m \u001B[43mtype_of_target\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43my\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    208\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m y_type \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m [\n\u001B[0;32m    209\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    210\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulticlass\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    213\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultilabel-sequences\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    214\u001B[0m     ]:\n\u001B[0;32m    215\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    216\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnknown label type: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00my_type\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. Maybe you are trying to fit a \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    217\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclassifier, which expects discrete classes on a \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    218\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mregression target with continuous values.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    219\u001B[0m         )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\main\\lib\\site-packages\\sklearn\\utils\\multiclass.py:387\u001B[0m, in \u001B[0;36mtype_of_target\u001B[1;34m(y, input_name)\u001B[0m\n\u001B[0;32m    385\u001B[0m \u001B[38;5;66;03m# Check multiclass\u001B[39;00m\n\u001B[0;32m    386\u001B[0m first_row \u001B[38;5;241m=\u001B[39m y[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m issparse(y) \u001B[38;5;28;01melse\u001B[39;00m y\u001B[38;5;241m.\u001B[39mgetrow(\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mdata\n\u001B[1;32m--> 387\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mxp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munique_values\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m (y\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(first_row) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m    388\u001B[0m     \u001B[38;5;66;03m# [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\u001B[39;00m\n\u001B[0;32m    389\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulticlass\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m suffix\n\u001B[0;32m    390\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\main\\lib\\site-packages\\sklearn\\utils\\_array_api.py:262\u001B[0m, in \u001B[0;36m_NumPyAPIWrapper.unique_values\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    261\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21munique_values\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m--> 262\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mnumpy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munique\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m<__array_function__ internals>:200\u001B[0m, in \u001B[0;36munique\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\main\\lib\\site-packages\\numpy\\lib\\arraysetops.py:274\u001B[0m, in \u001B[0;36munique\u001B[1;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001B[0m\n\u001B[0;32m    272\u001B[0m ar \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masanyarray(ar)\n\u001B[0;32m    273\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m axis \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 274\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43m_unique1d\u001B[49m\u001B[43m(\u001B[49m\u001B[43mar\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_inverse\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_counts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m    275\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mequal_nan\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mequal_nan\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    276\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _unpack_tuple(ret)\n\u001B[0;32m    278\u001B[0m \u001B[38;5;66;03m# axis was specified and not None\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\main\\lib\\site-packages\\numpy\\lib\\arraysetops.py:336\u001B[0m, in \u001B[0;36m_unique1d\u001B[1;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001B[0m\n\u001B[0;32m    334\u001B[0m     aux \u001B[38;5;241m=\u001B[39m ar[perm]\n\u001B[0;32m    335\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 336\u001B[0m     \u001B[43mar\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msort\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    337\u001B[0m     aux \u001B[38;5;241m=\u001B[39m ar\n\u001B[0;32m    338\u001B[0m mask \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mempty(aux\u001B[38;5;241m.\u001B[39mshape, dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mbool_)\n",
      "\u001B[1;31mTypeError\u001B[0m: '<' not supported between instances of 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "classifier = BaggingClassifier(n_estimators=10, random_state=0)\n",
    "classifier.fit(X_train, y_train)\n",
    "print(f\"Time taken: {time.perf_counter() - start} sec\")\n",
    "print(\"Train error rate: \", 1 - accuracy_score(classifier.predict(X_train), y_train))\n",
    "print(\"Test error rate: \", 1 - accuracy_score(classifier.predict(X_test), y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T18:28:13.623726600Z",
     "start_time": "2024-02-20T18:28:12.538536Z"
    }
   },
   "id": "f529c878fc0f47d8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ensemble_sizes = range(1, 51, 4)\n",
    "ensemble_sizes = range(50, 65, 4)\n",
    "train_error = []\n",
    "test_error = []\n",
    "\n",
    "for ensemble_size in ensemble_sizes:\n",
    "    model = BaggingClassifier(n_estimators=ensemble_size, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    train_error.append(1 - accuracy_score(model.predict(X_train), y_train))\n",
    "    test_error.append(1 - accuracy_score(model.predict(X_test), y_test))\n",
    "\n",
    "plt.plot(ensemble_sizes, train_error)\n",
    "plt.plot(ensemble_sizes, test_error)\n",
    "plt.xticks(ensemble_sizes)\n",
    "plt.xlabel(\"Number of estimators\")\n",
    "plt.ylabel(\"Error Rate\")\n",
    "plt.legend([\"Train\", \"Test\"])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a4ed7dce9dece53"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Random Forest (RF)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95bd5bc1020f8936"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "classifier = RandomForestClassifier(n_estimators=50, max_features=50, random_state=0)\n",
    "classifier.fit(X_train, y_train)\n",
    "print(f\"Time taken: {time.perf_counter()-start} sec\")\n",
    "print(\"Train error rate: \", 1 - accuracy_score(classifier.predict(X_train), y_train))\n",
    "print(\"Test error rate: \", 1 - accuracy_score(classifier.predict(X_test), y_test))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5508ef32df5123c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ensemble_sizes = range(1, 51, 4)\n",
    "for nr_features in [10, 50, 300, \"auto\"]:\n",
    "    error_rates = {\"train\":[], \"test\":[]}\n",
    "\n",
    "    for ensemble_size in ensemble_sizes:\n",
    "        model = RandomForestClassifier(n_estimators = ensemble_size, random_state = 0, max_features=nr_features)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        error_rates[\"train\"].append(1 - accuracy_score(model.predict(X_train), y_train))\n",
    "        error_rates[\"test\"].append(1 - accuracy_score(model.predict(X_test), y_test))\n",
    "    \n",
    "    plt.plot(ensemble_sizes, error_rates[\"train\"], label=f\"{nr_features}\", linestyle=\"--\", linewidth=2)\n",
    "    plt.plot(ensemble_sizes, error_rates[\"test\"], label=f\"{nr_features}\", linewidth=2)\n",
    "\n",
    "plt.xlabel(\"Number of trees\")\n",
    "plt.ylabel(\"Error Rate\")\n",
    "plt.xticks(ensemble_sizes)\n",
    "plt.legend(ncol=2)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "39ab4c2f87e5db4b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Returns importance of each feature\n",
    "pd.DataFrame({\"pixel\":np.arange(28**2), \"importance\": model.feature_importances_}).sort_values(\"importance\", ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "264ee47bad2cac4e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, let's use all the digits in the dataset. The ideal scenario:\n",
    "1. find the optimal number of estimators on training dataset (e.g. using Cross-Validation),\n",
    "2. train an ensemble model with optimal number of estimators (i.e. individual models) on training dataset,\n",
    "3. test the trained ensemble model on testing dataset."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34882a33409f9a1a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, y_train = mnist_train.iloc[:,1:], mnist_train.iloc[:,0]\n",
    "X_test, y_test = mnist_test.iloc[:,1:], mnist_test.iloc[:,0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99f70879d856cf96"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "classifier = BaggingClassifier(n_estimators=17, random_state=0) # Suppose, the optimal number of estimators is 17 for Bagging\n",
    "classifier.fit(X_train, y_train)\n",
    "print(f\"Time taken: {time.perf_counter() - start} sec\")\n",
    "print(\"Train accuracy: \", accuracy_score(classifier.predict(X_train), y_train))\n",
    "print(\"Test accuracy: \", accuracy_score(classifier.predict(X_test), y_test))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96289c97555543ae"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "classifier = RandomForestClassifier(n_estimators=45, random_state=0) # Suppose, the optimal number of estimators is 45 for RF\n",
    "classifier.fit(X_train, y_train)\n",
    "print(f\"Time taken: {time.perf_counter() - start} sec\")\n",
    "print(\"Train accuracy: \", accuracy_score(classifier.predict(X_train), y_train))\n",
    "print(\"Test accuracy: \", accuracy_score(classifier.predict(X_test), y_test))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96c6b874c406f547"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here, both classifiers overfit on training data, and the test accuracy for:\n",
    "1. Bagging should be around 92%, because Bagging uses all features (total: 764 features),\n",
    "2. Random Forest should be around 95%, because Random Forest does not use all features.\n",
    "\n",
    "The other 2 algorithms are implemented in similar ways as Bagging and Random Forest."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5220b5ebf913e276"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Weighted Voting"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff4d6919195b6060"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ca84958c1c0cf5e5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Stacking"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc7d5f85e5da168c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c1ed4cdc54220828"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
